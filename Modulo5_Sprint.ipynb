{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 5 Sprint\n",
    "\n",
    "## Tema\n",
    "\n",
    "**Aprendizaje de máquina supervisado**\n",
    "\n",
    "\n",
    "*Objetivo del proyecto (Competencias del módulo)*\n",
    "\n",
    "\n",
    "**Elaborar un modelo predictivo a partir de un set de datos utilizando técnicas de aprendizaje de máquina supervisado implementados en lenguaje Python para resolver un problema.**\n",
    "\n",
    "\n",
    "# Descripción del ejercicio\n",
    "\n",
    "\n",
    "## Contexto\n",
    "\n",
    "\n",
    "Utilizaremos un set de datos de las policias de New York del año 2009 y 2010. (2009_1perc.csv y 2010_1perc.csv) los cuales nos darán información de los procedimientos policiales realizados. Además se le entregará el diccionario de variables para que pueda consultar que significa cada categoría dentro de las variables.\n",
    "\n",
    "\n",
    "La variable respuesta 'arstmade' informa si los procedimientos policiales han terminado en arresto o no, y el objetivo será realizar un modelo de Machine Learning para predecir si un futuro procedimiento terminará en arresto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.- Enliste todas las librerías que utilizará**\n",
    "\n",
    "*Nota: Se recomienda ir actualizando la lista conforme las necesidades vaya teniendo durante el desarrollo de la prueba*\n",
    "\n",
    "\n",
    "**2.- Importación y revisión de los datos**  *Importe ambos sets. Dado que la fuente de datos proviene de la misma base, tienen las mismas columnas. Consolide ambos sets y reporte una exploración básica de los datos (número de filas/columnas, tipos de datos, estadísticas básicas, casos perdidos)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_pol_2009 = pd.read_csv('2009_1perc.csv')\n",
    "pro_pol_2010 = pd.read_csv('2010_1perc.csv')\n",
    "\n",
    "df_procedimientos_policiales = pd.concat([pro_pol_2009, pro_pol_2010]).reset_index()\n",
    "df_procedimientos_policiales = df_procedimientos_policiales.drop(columns=['index'])\n",
    "\n",
    "variable_respuesta = 'arstmade'\n",
    "\n",
    "df_procedimientos_policiales.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedimientos_policiales = df_procedimientos_policiales.replace(' ', np.nan)\n",
    "\n",
    "\n",
    "df_procedimientos_policiales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dimensiones_df = df_procedimientos_policiales.shape   # (11825, 112)\n",
    "info_df = df_procedimientos_policiales.info()  # dtypes: float64(7), int64(16), object(89)\n",
    "\n",
    "categorical = [var for var in df_procedimientos_policiales.columns if df_procedimientos_policiales[var].dtype=='O']\n",
    "integer_variable = [var for var in df_procedimientos_policiales.columns if df_procedimientos_policiales[var].dtype=='int64']\n",
    "float_variable = [var for var in df_procedimientos_policiales.columns if df_procedimientos_policiales[var].dtype=='float64']\n",
    "\n",
    "df_categorical = df_procedimientos_policiales[categorical]\n",
    "df_integer_variable = df_procedimientos_policiales[integer_variable]\n",
    "df_float_variable = df_procedimientos_policiales[float_variable]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_integer_variable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_float_variable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int_nulos = df_integer_variable.isnull().sum()\n",
    "df_flo_nulos = df_float_variable.isnull().sum()\n",
    "df_cat_nulos = df_categorical.isnull().sum()\n",
    "\n",
    "\n",
    "df_nulos = pd.concat([df_int_nulos, df_cat_nulos, df_flo_nulos])\n",
    "df_nulos = df_nulos[(df_nulos != 0)]\n",
    "\n",
    "columna = ['Cantidad']\n",
    "\n",
    "df_nulos = pd.DataFrame(df_nulos, columns=columna)\n",
    "\n",
    "df_nulos['Porcentaje'] = round((df_nulos / df_procedimientos_policiales.shape[0]) * 100, 2)\n",
    "\n",
    "df_nulos = df_nulos.sort_values('Cantidad', ascending=False)\n",
    "\n",
    "cantidad_registros_nulos = df_nulos['Cantidad'].sum()   # 156956\n",
    "\n",
    "df_nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_nulos = list(df_nulos.sort_values('Cantidad', ascending=False).index)\n",
    "\n",
    "df_correlacion = pd.DataFrame(df_procedimientos_policiales[columnas_nulos].notnull().astype(int))\n",
    "df_1 = pd.DataFrame(df_procedimientos_policiales[variable_respuesta].replace('N', 0).replace('Y', 1))\n",
    "\n",
    "\n",
    "df_correlacion['Variable Respuesta'] = df_1\n",
    "\n",
    "\n",
    "df_correlacion = df_correlacion.drop(['zip', 'state', 'aptnum', 'premtype', 'rescode', 'othfeatr'], axis=1)\n",
    "\n",
    "matriz_correlacion = df_correlacion.corr()\n",
    "\n",
    "figure = plt.figure(figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(data=matriz_correlacion, cmap='coolwarm', vmin=-1, vmax=1, annot=True, fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_procedimientos_policiales['city'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_2_valores = []\n",
    "\n",
    "for columna in df_procedimientos_policiales:\n",
    "    if len(df_procedimientos_policiales[columna].value_counts())  == 2:\n",
    "        columnas_2_valores.append(columna)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Columnas con dos valores: \",columnas_2_valores)\n",
    "print(len(columnas_2_valores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_valores = df_procedimientos_policiales[columnas_2_valores]\n",
    "#df_2_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Esta celda tiene códifgo que no es necesariamente ejecutable ya que mediante la función genera gráficos para todas variables de la lista df_2_valores\n",
    "# Si quiere activar la celda, eliminar las docstrings\n",
    "\n",
    "def distribution_plots(df, columns=3):\n",
    "    \n",
    "    rows = np.ceil(df.shape[1] / columns).astype(int)\n",
    "    height = rows * 3.5\n",
    "    fig = plt.figure(figsize=(12, height))\n",
    " \n",
    "    for n, i in enumerate(df.columns):\n",
    "        \n",
    "        if df[i].dtype in ('object', 'int64') :\n",
    "            fig.add_subplot(rows, columns, n+1)\n",
    "            ax = sns.countplot(x=i, data=df)\n",
    "            plt.title(i)\n",
    "            plt.xlabel('')\n",
    "            for p in ax.patches:\n",
    "                height = p.get_height()\n",
    "                ax.text(p.get_x()+p.get_width()/2., height + .5,\n",
    "                    '{:1.2f}'.format(height/len(df[i])), ha=\"center\")\n",
    "\n",
    "        if df[i].dtype == 'float64':\n",
    "            fig.add_subplot(rows, columns, n+1)\n",
    "            ax = sns.distplot(df[i])\n",
    "            plt.title(i)\n",
    "            plt.xlabel('')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "distribution_plots(df_2_valores)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_procedimientos_policiales['arstmade'].describe())\n",
    "\n",
    "print('=' * 50)\n",
    "\n",
    "print(df_procedimientos_policiales['arstmade'].value_counts())\n",
    "\n",
    "print('=' * 50)\n",
    "\n",
    "print(f'La cantidad total de registros nulos en el data frame es: {cantidad_registros_nulos}')\n",
    "print(f'Corresponde al {(cantidad_registros_nulos/df_procedimientos_policiales.size * 100):.2f} % del total de registros del DataFrame')\n",
    "print('\\n' + f'La cantidad de filas en el DataFrame es {df_procedimientos_policiales.shape[0]}')\n",
    "print(f'La cantidad de columnas en el DataFrame es {df_procedimientos_policiales.shape[1]}')\n",
    "print('\\n' + f'Variables Integer: {df_integer_variable.shape[1]}')\n",
    "print(f'Variables Float: {df_float_variable.shape[1]}')\n",
    "print(f'Variables Categóricas: {df_categorical.shape[1]}')\n",
    "print(f'La cantidad de variables que incluyen registros nulos es {df_nulos.shape[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan los datos en dos variables y se concatenan en *'df_procedimientos_policiales'*, DataFrame del cual se realizará el estudio.  Las dimensiones de este DataFrame es 11825 filas por 112 columnas.  En primera visualización se obtiene vista de registros vacíos pero que no son considerados por Python como nulos ya que son registros que contienen ' ' (espacio) caracter lo que es distinto a vacío o nulo.  Se reemplazan los valores (espacio) por el valor np.nan.  Se exploran el tipo de dato de las variables obteniendo: 89 variables categóricas (se restan 6 variables categóricas al df original cuando se realiza el paso de replace); 16 variables Integer y 7 variables Float.  Decido observar en detalle la calidad de los datos *por cada tipo de dato* y me parece útil crear DataFrames *por cada tipo de dato* y explorarlos en profundidad.  Algunas observaciones:\n",
    "\n",
    "- 6 de las 7 variables float no contiene datos en su totalidad (todos Nan), por consiguiente estas variables no tienen ninguna influencia en la variable target y se sugiere eliminar del modelo pues no aporta poder predictivo.  Estas variables son las mismas que se reclasificaron como float luego de la accion .replace().\n",
    "\n",
    "- Al reemplazar los registros con caracter (espacio) ' ', se pudo descubrir los valores perdidos que en total del DataFrame asciende a 156.956 registros y corresponde al 11,85% del total de registros del DataFrame\n",
    "\n",
    "- Se observa que en las variables integer existen datos que no aportan valor estadístico como 'Unnamed:0' y 'dob'.  Se sugiere eliminarlas del modelo.  Se aprecia tambien que existen variables del tipo DatTime como 'year', 'datestop', 'timestop'.\n",
    "\n",
    "- Se quiere observar el comportamiento de las variables que tienen valores binarios para descubrir desbalances que no aporten valor al modelo.  Se obtiene que de las 112 columnas, 60 contienen datos binarios.  Se incluye función que permite graficar los datos comparativos de estas 60 variables.  Con este resultado podemos observar que el 6% de los procedimientos concluyen en arresto según muestra su gráfico.  También se cuentan 11 de las 60 variables que tienen un desbalancel del 100% por este motivo también se concluye que no tiene valor para el modelo y deben se eliminadas.\n",
    "\n",
    "- En estudio de índices de correlación entre la variables respuesta y las 28 variables que contienen registros nulos se obtiene que, con excepción de la variable 'arstoffn', ninguna de las otras 27 variables tiene un indice de correlación significante respecto a la variable respuesta.  Si bien un índice de correlación no siempre suele explicar la verdadera naturaleza de su valor, en este caso, yo apunto a que no tienen valor relevante para el modelo y se deberían eliminar.  Se incluye mapa de calor de matriz de correlación.\n",
    "\n",
    "- Podrían existir observaciones más finas sobre la calidad de los datos, como los valores únicos, cambios de datatype u otros pero todo trabajo más fino se debiese aplicar posterior a la eliminación de columnas que no aportan valor al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Preprocesamiento de datos \n",
    "\n",
    "Habrá notado que los datos parecen tener ciertas inconsistencias. Siga los siguientes pasos para limpiar este set:\n",
    "\n",
    "● 3.1 Obtenga una lista con todas las variables categóricas que tengan entre 2 y 99 categorías (inclusive). (hint: son las variables tipo categóricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_2_a_99_valores = []\n",
    "\n",
    "for columna in df_procedimientos_policiales:\n",
    "    if len(df_procedimientos_policiales[columna].value_counts())  >= 2 | len(df_procedimientos_policiales[columna].value_counts() <= 99):\n",
    "        if df_procedimientos_policiales[columna].dtype=='O':\n",
    "            columnas_2_a_99_valores.append(columna)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Columnas con valores entre 2 y 99 ambos inclusive: \",columnas_2_a_99_valores)\n",
    "print(f'El total de variables que tienen entre 2 y 99 categorias de registros es {len(columnas_2_a_99_valores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● 3.2 Reemplace las siguientes clases faltantes:\n",
    "\n",
    "- Si alguna categoría de las columnas officrid, offshld o offverb es igual a \"\" cámbielo a 'N' y en caso contrario déjelo como 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_procedimientos_policiales['officrid'] = np.where(df_procedimientos_policiales['officrid'].isna(), 'N', 'Y')\n",
    "df_procedimientos_policiales['offshld'] = np.where(df_procedimientos_policiales['offshld'].isna(), 'N', 'Y')\n",
    "df_procedimientos_policiales['offverb'] = np.where(df_procedimientos_policiales['offverb'].isna(), 'N', 'Y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*- Si alguna categoría de las columnas sector, trhsloc o beat es igual a \"\" (o NA, dependiendo de cómo haya categorizado la base de datos), cámbielo a 'U' y en caso contrario mantenga su valor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_procedimientos_policiales['sector'] = np.where(df_procedimientos_policiales['sector'].isna(), 'U', df_procedimientos_policiales['sector'])\n",
    "df_procedimientos_policiales['trhsloc'] = np.where(df_procedimientos_policiales['trhsloc'].isna(), 'U', df_procedimientos_policiales['trhsloc'])\n",
    "df_procedimientos_policiales['beat'] = np.where(df_procedimientos_policiales['beat'].isna(), 'U', df_procedimientos_policiales['beat'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota, los valores significan {N: No, Y: Yes, U: Unknown}*\n",
    "\n",
    "\n",
    "*● 3.3 Transforme las columnas ht_feet junto con ht_inch en una única columna (de la forma \"ht_feet.ht_inch\") llamado 'meters' (hint: transforme con el siguiente cálculo: metros = (pies+pulgadas)*0.3048)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pies_a_metros = 0.3048\n",
    "pulgadas_a_metros = 0.0254\n",
    "\n",
    "df_procedimientos_policiales['ht_feet'] = df_procedimientos_policiales['ht_feet'] * pies_a_metros\n",
    "df_procedimientos_policiales['ht_inch'] = df_procedimientos_policiales['ht_inch'] * pulgadas_a_metros\n",
    "df_procedimientos_policiales['metros'] = df_procedimientos_policiales['ht_feet'] + df_procedimientos_policiales['ht_inch']\n",
    "\n",
    "df_procedimientos_policiales = df_procedimientos_policiales.drop(columns=['ht_feet', 'ht_inch'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*● 3.4 Note que la fecha viene en un formato MMDDAAAA en la columna datestop. Genere 2 nuevas columnas llamadas month y year que solo tenga el mes y el año respectivamente.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedimientos_policiales['year'] = pd.to_datetime(df_procedimientos_policiales['datestop'], format='%m%d%Y').dt.year\n",
    "df_procedimientos_policiales['month'] = pd.to_datetime(df_procedimientos_policiales['datestop'], format='%m%d%Y').dt.month\n",
    "\n",
    "\n",
    "#df_procedimientos_policiales['year'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_procedimientos_policiales['month'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*● 3.5 Filtre su DataFrame y solo deje las columnas seleccionadas en el punto 3.1, el mes, el año, los metros y la edad. Luego solo deje los registros cuyas edades estén entre 18 y 100 años, ambos inclusive.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_seleccionadas = columnas_2_a_99_valores + ['month', 'year', 'metros', 'age', 'race']\n",
    "\n",
    "df_filtrado = df_procedimientos_policiales[columnas_seleccionadas] \n",
    "df_filtrado = df_filtrado[(df_filtrado['age'] >= 18) & (df_filtrado['age'] <= 100)]\n",
    "\n",
    "#df_filtrado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Análisis exploratorio\n",
    "\n",
    "● 4.1 Estudie la variable respuesta por si sola (arstmade), puede ayudarse de un gráfico. Comente\n",
    "\n",
    "● 4.2.- Estudie la relación de la variable respuesta en comportamiento con la raza (race), comente.\n",
    "\n",
    "● 4.3 Estudie la relación de la variable respuesta en comportamiento con la sexo (sex), comente.\n",
    "\n",
    "● 4.3 Estudie la relación de la variable respuesta en comportamiento con la sexo y la edad en su conjunto, comente.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado[variable_respuesta]\n",
    "tabla_de_frecuencia = df_filtrado[variable_respuesta].value_counts()\n",
    "cantidad_no_arresto = tabla_de_frecuencia[0]\n",
    "cantidad_arresto = tabla_de_frecuencia[1]\n",
    "porcentaje_no_arresto =  cantidad_no_arresto / len(df_filtrado) * 100\n",
    "porcentaje_arresto = cantidad_arresto / len(df_filtrado) * 100\n",
    "\n",
    "raza_arstmade = [variable_respuesta, 'race']\n",
    "df_raza_arstmade = df_filtrado[raza_arstmade]\n",
    "df_raza_arstmade['arstmade'] =  df_raza_arstmade['arstmade'].map({'N':0, 'Y':1})\n",
    "tabla_de_frecuencia_raza = pd.crosstab(df_raza_arstmade['race'], df_raza_arstmade['arstmade'])\n",
    "\n",
    "sexo_arstmade =  ['arstmade', 'sex']\n",
    "df_sexo_arstmade = df_filtrado[sexo_arstmade]\n",
    "\n",
    "edad_sexo = ['arstmade', 'age', 'sex']\n",
    "df_edad_sexo =  df_filtrado[edad_sexo]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "sns.barplot(ax=axes[0], x=tabla_de_frecuencia.index, y=tabla_de_frecuencia.values, palette='pastel')\n",
    "axes[0].set_title('Tabla de Frecuencia Procedimientos Policiales', fontsize=10)\n",
    "axes[0].set_xlabel('Arrestos Realizados', fontsize=15)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=15)\n",
    "axes[0].annotate(cantidad_no_arresto, xy=(0, 9432), xytext=(-0.1, 7000), fontsize=10,\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "axes[0].annotate(f'{round(porcentaje_no_arresto, 2)} %', xy=(0.8, 5000), xytext=(-0.2, 5000), fontsize=10)\n",
    "axes[0].annotate(cantidad_arresto, xy=(1, 646), xytext=(0.92, 3200), fontsize=10,\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "axes[0].annotate(f'{round(porcentaje_arresto, 2)} %', xy=(0.9, 200), xytext=(0.9, 200), fontsize=10)\n",
    "\n",
    "sns.countplot(ax=axes[1], data=df_raza_arstmade, x='race', hue='arstmade', palette='pastel')\n",
    "axes[1].set_title('No Arrestos vs Arrestos por Raza')\n",
    "axes[1].set_xlabel('Raza', fontsize=15)\n",
    "axes[1].set_ylabel('Cantidad', fontsize=10)\n",
    "axes[1].legend(title='Arrestado', labels=['No', 'Sí'])\n",
    "\n",
    "\n",
    "sns.countplot(ax=axes[2], data=df_sexo_arstmade, x='sex', hue='arstmade', palette='pastel')\n",
    "axes[2].set_title('No Arrestos vs Arrestos por Género')\n",
    "axes[2].set_xlabel('Género', fontsize=15)\n",
    "axes[2].set_ylabel('Cantidad', fontsize=10)\n",
    "axes[2].legend(title='Arrestado', labels=['No', 'Sí'])\n",
    "#sns.barplot(ax=axes[1], data=df_raza_arstmade, x='arstmade', y=df_raza_arstmade.values, palette='pastel')\n",
    "\n",
    "#sns.scatterplot(ax=axes[3], data=df_edad_sexo, x='sex', y='age', hue='arstmade', palette='dark', alpha=0.4)\n",
    "sns.violinplot(ax=axes[3], data=df_edad_sexo, x='sex', y='age', split=True, hue='arstmade', palette='pastel', inner='quartile')\n",
    "axes[3].set_title('No Arrestos vs Arrestos por Género y Edad')\n",
    "axes[3].set_xlabel('Género', fontsize=15)\n",
    "axes[3].set_ylabel('Edad', fontsize=10)\n",
    "axes[3].legend(title='Arrestado', labels=['No', 'Sí'])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según observación de los gráficos generados para las indicaciones del ejercicio puedo comentar los siguiente:\n",
    "\n",
    "1. De un total de 10.078 controles policiales registrados válidos luego del filtro de edad, se obtiene que solo 646 de ellos concluye en arresto lo que equivale al 6,41 % de los controles realizados.  La cantidad de controles que no terminan en arresto equivale a 9.432 registros.  Solo en base a los datos de este gráfico no es posible obtener mayores certezas respecto al comportamiento.\n",
    "\n",
    "2. En el segundo gráfico se puede observar una tendencia, o sesgo, respecto a la distribución de los controles si los segregamos por raza.  Se aprecia claramente que las personas categorizadas con raza B son las que concentran la mayor cantidad de registros realizados, esto constituye un claro sesgo discrimandor racial.  Se puede ver también que existe sesgo con al menos otros dos grupos étnicos más y los demás grupos se comportan en distribuciones más parecidas a la normal.  Se concluye que bajo pertenencia a ciertas etnias es más probable que seas controlado sin embargo no hay evidencias que puedan concluir que debido a tu etnia puedas ser arrestado.\n",
    "\n",
    "3. Se observa tendencia a mayores controles realizados a sujetos de género másculino, en cantidad también son la categoría que concentra mayor cantidad de detenidos.  Al igual que la variable raza, no existe evidencia suficiente para asegurar que el género es constitutivo de terminar bajo arresto si eres sometido a un control policial.  Si se puede concluir la probabilidad de ser controlado respecto a tu género.\n",
    "\n",
    "4. La diferencia de magnitud entre los controles realizados por género me orienta a graficar en este caso, mediante un gráfico de violín para poder observar el comportamiento de los datos bajos las variables 'edad y sexo' en conjunto.  El gráfico de violín nos permite observar comportamientos de distribución de sus datos y por lo tanto probabilidad de distribución.  De todas maneras el análisis realizado me permite concluir que, con excepcion de arrestos realizados genero Z, todas las otras variables contienen sus picos de densidad en un rango cercano de diferencia, también comparten rangos cercanos de diferencia los valores de sus cuartiles e incluso la forma de su curva de distribución que concentra la mayor densidad alrededor de los 20 años inclinando la curva hacia la izquierda del eje, en cambio el 'género Z arrestado' muestra una distribución más similar a la normal, su moda parece estar bien alineada con su media y la curva es más ancha pero sus métricas no comparten el mismo comportamiento de las métricas de las demás categorías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● 4.4 Recodifique la variable respuesta a 1 y 0. Donde 0 es N y 1 es Y\n",
    "\n",
    "● 4.5 Muestre en un gráfico la probabilidad que un individuo sea arrestado, condicional al género y a la raza. ¿qué implicancias éticas tienen algunas conclusiones de lo que observa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado['arstmade'] =  df_filtrado['arstmade'].map({'N':0, 'Y':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probabilidad_arresto = ['arstmade', 'race', 'sex']\n",
    "df_probabilidad_arresto = df_filtrado[probabilidad_arresto]\n",
    "df_probabilidad_arresto = df_probabilidad_arresto[df_probabilidad_arresto['arstmade'] == 1]\n",
    "\n",
    "sns.countplot(data=df_probabilidad_arresto, x='sex', hue='race', palette='pastel')\n",
    "\n",
    "plt.title('Gráfico de Probabilidad Arrestos por Género y Raza')\n",
    "plt.xlabel('Género', fontsize=15)\n",
    "plt.ylabel('Frecuencia', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente la raza B es la que tiene mayor ocurrencia.  Como hemos observado previamente, esto deriva de un sesgo en la realización de controles policiales siendo la raza B la más susceptible a prejuicio, esto deriva en que es por lejos más controlada.  El solo hecho de ser el de un grupo étnico prejuiciado incide en la cantidad de casos que terminan en arrestos.  Otras dos razas más conforman junto con raza B, la mayor cantidad de casos por lo que podemos concluir que la tasa de arrestos está condicionada por el grupo étnico al cual pertences pues estás más expuesto a ser controlado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Determinar si el procedimiento policial concluirá en alguna acción violenta.\n",
    "\n",
    "\n",
    "Los atributos que tienen el prefijo pf (['pf_hands'],['pf_wall'], ['pf_grnd'], ['pf_drwep'], ['pf_ptwep'],['pf_baton'],['*pf_hcuff'], ['pf_pepsp'] y ['pf_other']) indican si hubo fuerza fisica utilizada por el oficial al momento del procedimiento, con la marca 'Y'.Genere una nueva variable llamada 'violencia' la cual sea 1 si en cualquiera de las 9 variables pf hubo alguna 'Y', y 0 en otro caso. Luego indique el porcentaje de casos que terminaron con violencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_violencia = ['pf_hands', 'pf_wall', 'pf_grnd', 'pf_drwep', 'pf_ptwep', 'pf_baton', 'pf_hcuff', 'pf_pepsp', 'pf_other']\n",
    "\n",
    "df_lista_violencia = df_filtrado[lista_violencia]\n",
    "df_lista_violencia['violencia'] = df_lista_violencia.apply(lambda row: row.str.contains('Y').any(), axis=1)\n",
    "\n",
    "df_lista_violencia['violencia'] = df_lista_violencia['violencia'].astype(int)\n",
    "conteo_porcentaje_violencia = df_lista_violencia['violencia'].value_counts()\n",
    "\n",
    "porcentaje_no_violento = conteo_porcentaje_violencia[0] / df_filtrado.shape[0] * 100\n",
    "porcentaje_violento =  conteo_porcentaje_violencia[1] / df_filtrado.shape[0] * 100\n",
    "\n",
    "print(conteo_porcentaje_violencia[1])\n",
    "\n",
    "sns.barplot(x=conteo_porcentaje_violencia.index, y=conteo_porcentaje_violencia.values, palette='pastel', label={'No':0, 'Si':1})\n",
    "\n",
    "plt.title('Gráfico de Casos Procedimientos con Violencia')\n",
    "plt.xlabel('Violencia Aplicada')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.xticks([0, 1], ['No', 'Si'])\n",
    "plt.annotate(f'{porcentaje_no_violento:.2f} %', xy=(0, 7641), xytext=(-0.1, 4000), fontsize=10)\n",
    "plt.annotate(f'{porcentaje_violento:.2f} %', xy=(1, 2437), xytext=(0.93, 900), fontsize=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violencia = df_lista_violencia['violencia']\n",
    "\n",
    "df_filtrado['violencia'] = df_violencia\n",
    "#df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado['city'] = df_filtrado['city'].replace('STATEN IS', 'STATEN ISLAND')\n",
    "df_filtrado = df_filtrado.drop(columns=['xcoord', 'ycoord'])\n",
    "\n",
    "for var in lista_violencia:\n",
    "\n",
    "    df_filtrado = df_filtrado.drop(columns=[var])\n",
    "\n",
    "\n",
    "#df_filtrado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan del dataframe las columnas que fueron utilizadas para crear la variable violencia pues ahora tienen un indicador que las representa con mejor respecto los parámetros del estudio (variable 'violencia')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtrado_2_valores = []\n",
    "\n",
    "for columna in df_filtrado:\n",
    "    if len(df_filtrado[columna].value_counts())  > 2:\n",
    "            filtrado_2_valores.append(columna)\n",
    "\n",
    "#filtrado_2_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(filtrado_2_valores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' CATEGORÍAS POR VARIABLE '.center(35, '='))\n",
    "\n",
    "for var in filtrado_2_valores:\n",
    "    print(f'{var} '.ljust(20, '.') + f' {len(df_filtrado[var].value_counts())}'.rjust(15,'.'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_en_addrnum = df_filtrado['addrnum'].isna().sum()\n",
    "nan_en_sumoffen = df_filtrado['sumoffen'].isna().sum()\n",
    "\n",
    "valores_en_sumoffen = df_filtrado['sumoffen'].value_counts()\n",
    "\n",
    "df_filtrado['beat'] = df_filtrado['beat'].str.strip()\n",
    "valores_en_beat = df_filtrado['beat'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' CATEGORÍAS POR VARIABLE '.center(35, '='))\n",
    "\n",
    "for var in filtrado_2_valores:\n",
    "    print(f'{var} '.ljust(20, '.') + f' {len(df_filtrado[var].value_counts())}'.rjust(15,'.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df_filtrado.drop(columns=['addrnum', 'sumoffen'])\n",
    "\n",
    "filtrado_2_valores.remove('addrnum')\n",
    "filtrado_2_valores.remove('sumoffen')\n",
    "\n",
    "#df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las 63 columnas que quedan luego del ajuste al dataframe, 52 corresponden a variables binarias y 11 son variables multicategoricas no binarias.\n",
    "\n",
    "Se decide excluir del modelo las variables 'addrnum' que contenía 2065 valores distintos y 5850 valores nulos.  Los registros tampoco eran interpretables ni aportaban valor al modelo.  Se excluye también la variable 'summoffend' por motivos de la calidad de sus datos ya que tiene un total de 340 valores distintos, poco confiables y del total de registros tiene un total de 9.366 valores vacíos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.- Modelación \n",
    "\n",
    "● 6.1 Genere las variables dummies correspondientes (Tenga cuidado de no utilizar variables que expliquen lo mismo, ¡recuerde que acaba de crear una variable a partir de otras!, además recuerde que creó una variable numérica que es una categoría :) ). Luego genere los sets de train-test utilizando el año 2009 para entrenar, y el año 2010 para testear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(df_filtrado.apply(pd.unique))\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado['recstat'] = df_filtrado['recstat'].replace('A', 0)\n",
    "df_filtrado = df_filtrado.replace('N', 0)\n",
    "df_filtrado = df_filtrado.replace('Y', 1)\n",
    "df_filtrado['linecm'] = df_filtrado['linecm'].str.strip()\n",
    "df_filtrado['linecm'] = df_filtrado['linecm'].replace(np.nan, 0)\n",
    "df_filtrado['inout'] = df_filtrado['inout'].replace('O', 0)\n",
    "df_filtrado['inout'] = df_filtrado['inout'].replace('I', 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_lista = ['sex', 'haircolr', 'eyecolor', 'city', 'sector', 'beat', 'month', 'race', 'trhsloc']\n",
    "\n",
    "df_filtrado = pd.get_dummies(df_filtrado, columns=dummies_lista)\n",
    "df_filtrado = df_filtrado.replace(True, 1)\n",
    "df_filtrado =  df_filtrado.replace(False,0)\n",
    "#df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preparacion_datos_entrenamiento = df_filtrado[df_filtrado['year'] == 2009]\n",
    "preparacion_datos_testeo = df_filtrado[df_filtrado['year'] == 2010]\n",
    "\n",
    "preparacion_datos_entrenamiento = preparacion_datos_entrenamiento.drop('year', axis=1)\n",
    "preparacion_datos_testeo = preparacion_datos_testeo.drop('year', axis=1)\n",
    "\n",
    "X_train = preparacion_datos_entrenamiento.drop('arstmade', axis=1)\n",
    "X_test = preparacion_datos_testeo.drop('arstmade', axis=1)\n",
    "\n",
    "y_train = preparacion_datos_entrenamiento['arstmade']\n",
    "y_test = preparacion_datos_testeo['arstmade']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● 6.2 Entrene 4 modelos de clásificación y reporte el mejor modelo bajo algún criterio. Utilice validación cruzada de al menos 2 folds para probar distintos hiperparámetros para cada modelo (puede probar cualquier hiperparámetro, pero debe ser al menos uno)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimador Arbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarda aproximadamente 20 segundos en cargar\n",
    "\n",
    "modelo_clasificador_arbol_decision = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "parametros = {'criterion': ['gini', 'entropy'], 'max_depth': [1, 3, 5, 7, 9]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=modelo_clasificador_arbol_decision, param_grid=parametros, cv=10, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "resultados = pd.DataFrame(grid_search.cv_results_)\n",
    "mejores_parametros = grid_search.best_params_\n",
    "\n",
    "print(' MEJORES HIPERPARÁMETROS '.center(40, '=') + '\\n')\n",
    "print('CRITERIO '.ljust(25, '.') + f' {mejores_parametros[\"criterion\"]}'.rjust(15, '.') + '\\n\\n' + 'PROFUNDIDAD '.ljust(25, '.') + f' {mejores_parametros[\"max_depth\"]}'.rjust(15, '.'))\n",
    "print('\\n' + '=' * 40)\n",
    "\n",
    "\n",
    "print('\\n' + ' MSE por Combinación de Hiperparámetros  '.center(68, '=') + '\\n')\n",
    "print(resultados[['param_criterion', 'param_max_depth', 'mean_test_score', 'mean_train_score']])\n",
    "print('\\n' +  '=' * 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_clasificador_arbol_decision_2 = DecisionTreeClassifier(random_state=42, max_depth=3, criterion= 'entropy')\n",
    "modelo_clasificador_arbol_decision_2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = modelo_clasificador_arbol_decision_2.predict(X_test)\n",
    "mse_modelo_clasificador_arbol_decision_2 = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "informe_clasificacion = classification_report(y_test, y_pred)\n",
    "\n",
    "sumatoria_matriz_confusion =  np.sum(matriz_confusion)\n",
    "matriz_confusion_porcentajes =  matriz_confusion / sumatoria_matriz_confusion * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarda aproximadamente 17 segundos en cargar\n",
    "\n",
    "\n",
    "modelo_clasificacion_random_forest = RandomForestClassifier(random_state=42)\n",
    "modelo_clasificacion_random_forest.fit(X_train, y_train)\n",
    "\n",
    "parametros_gscvrf = {'n_estimators': [50, 100, 200], 'max_depth': [2, 10, 20]}\n",
    "\n",
    "grid_searchrf = GridSearchCV(estimator=modelo_clasificacion_random_forest, param_grid=parametros_gscvrf, cv=3, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_searchrf.fit(X_train, y_train)\n",
    "\n",
    "resultados_rf = pd.DataFrame(grid_searchrf.cv_results_)\n",
    "mejores_parametros_rf = grid_searchrf.best_params_\n",
    "\n",
    "print(' MEJORES HIPERPARÁMETROS '.center(40, '=') + '\\n')\n",
    "print('N Estimadores '.ljust(25, '.') + f' {mejores_parametros_rf[\"n_estimators\"]}'.rjust(15, '.') + '\\n\\n' + 'PROFUNDIDAD '.ljust(25, '.') + f' {mejores_parametros_rf[\"max_depth\"]}'.rjust(15, '.'))\n",
    "print('\\n' + '=' * 40)\n",
    "\n",
    "\n",
    "print('\\n' + ' MSE por Combinación de Hiperparámetros  '.center(68, '=') + '\\n')\n",
    "print(resultados_rf[['param_n_estimators', 'param_max_depth', 'mean_test_score', 'mean_train_score']])\n",
    "print('\\n' +  '=' * 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_clasificacion_random_forest_sugerido = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "modelo_clasificacion_random_forest_sugerido.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred_rfs = modelo_clasificacion_random_forest_sugerido.predict(X_test)\n",
    "mse_modelo_clasificador_random_forest_rfs = mean_squared_error(y_test, y_pred_rfs)\n",
    "\n",
    "matriz_confusion_rfs = confusion_matrix(y_test, y_pred_rfs)\n",
    "informe_clasificacion_rfs = classification_report(y_test, y_pred_rfs)\n",
    "\n",
    "sumatoria_matriz_confusion_rfs =  np.sum(matriz_confusion_rfs)\n",
    "matriz_confusion_porcentajes_rfs =  matriz_confusion_rfs / sumatoria_matriz_confusion_rfs * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarda aproximadamente 45 segundos en cargar\n",
    "\n",
    "\n",
    "diccionario_parametros = {'kernel': ['linear', 'rbf'], 'C' : [2, 4]}\n",
    "\n",
    "modelo_SVM = SVC(random_state=42)\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=modelo_SVM, param_grid=diccionario_parametros, cv=2)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "mejores_parametros_svm = grid_search_svm.best_params_\n",
    "mejor_modelo_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "\n",
    "print(' RESULTADOS '.center(90, '=') + '\\n')\n",
    "print('Mejor combinación de parámetros '.ljust(40, '.') + f' {mejor_modelo_svm}'.rjust(50, '.'))\n",
    "print('\\n' + '=' * 90)\n",
    "\n",
    "print('\\n' + ' MSE por Combinación de Hiperparámetros  '.center(68, '=') + '\\n')\n",
    "print(resultados_rf[['param_n_estimators', 'param_max_depth', 'mean_test_score', 'mean_train_score']])\n",
    "print('\\n' +  '=' * 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarda cerca de 40 segundos en cargar\n",
    "\n",
    "modelo_clasficicacion_svm_s = SVC(C=2,  kernel='linear', random_state=42)\n",
    "modelo_clasficicacion_svm_s.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_s = modelo_clasficicacion_svm_s.predict(X_test)\n",
    "mse_modelo_clasificador_svm_s = mean_squared_error(y_test, y_pred_svm_s)\n",
    "\n",
    "matriz_confusion_svm_s = confusion_matrix(y_test, y_pred_svm_s)\n",
    "informe_clasificacion_svm_s= classification_report(y_test, y_pred_svm_s)\n",
    "\n",
    "sumatoria_matriz_confusion_svm_s =  np.sum(matriz_confusion_svm_s)\n",
    "matriz_confusion_porcentajes_svm_s =  matriz_confusion_svm_s / sumatoria_matriz_confusion_svm_s * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarda cerca de 21 segundos en cargar\n",
    "\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "\n",
    "parametros_lr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'max_iter': [10, 50, 100, 250]\n",
    "}\n",
    "\n",
    "# Realiza la búsqueda en cuadrícula\n",
    "grid_search_lr = GridSearchCV(estimator=logistic_regression, param_grid=parametros_lr, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "resultados_lr = pd.DataFrame(grid_search_lr.cv_results_)\n",
    "# Imprime los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_search_lr.best_params_)\n",
    "\n",
    "# Obtiene el mejor modelo entrenado\n",
    "mejor_modelo_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "# Realiza predicciones con el mejor modelo\n",
    "predicciones_lr = mejor_modelo_lr.predict(X_test)\n",
    "\n",
    "\n",
    "print('\\n' + ' MSE por Combinación de Hiperparámetros  '.center(68, '=') + '\\n')\n",
    "print(resultados_lr[['param_C', 'param_max_iter', 'mean_test_score', 'mean_train_score']])\n",
    "print('\\n' +  '=' * 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_regresion_logistica_s = LogisticRegression(random_state=42, C=1, max_iter=100)\n",
    "modelo_regresion_logistica_s.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = modelo_regresion_logistica_s.predict(X_test)\n",
    "\n",
    "mse_modelo_clasificador_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "matriz_confusion_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "informe_clasificacion_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "sumatoria_matriz_confusion_lr =  np.sum(matriz_confusion_lr)\n",
    "matriz_confusion_porcentajes_lr =  matriz_confusion_lr / sumatoria_matriz_confusion_lr * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print('\\n' + 'MSE ÁRBOL DE DECISIÓN '.ljust(30,'.') + f' {mse_modelo_clasificador_arbol_decision_2:.4f}'.rjust(10, '.'))\n",
    "\n",
    "print('=' * 60 + '\\n')\n",
    "print('MATRIZ DE CONFUSIÓN ARBOL DE DECISION\\n')\n",
    "print(matriz_confusion)\n",
    "print('\\n' + '=' * 60)\n",
    "\n",
    "\n",
    "print('INFORME DE CLASIFICACIÓN ARBOL DE DECISIÓN\\n')\n",
    "print(informe_clasificacion)\n",
    "print('_' * 60 + '\\n')\n",
    "\n",
    "\n",
    "print('\\n' + 'MSE RANDOM FOREST '.ljust(30,'.') + f' {mse_modelo_clasificador_random_forest_rfs:.4f}'.rjust(10, '.'))\n",
    "\n",
    "print('=' * 60 + '\\n')\n",
    "print('MATRIZ DE CONFUSIÓN RANDOM FOREST\\n')\n",
    "print(matriz_confusion_rfs)\n",
    "print('\\n' + '=' * 60)\n",
    "\n",
    "print('INFORME DE CLASIFICACIÓN RANDOM FOREST\\n')\n",
    "print(informe_clasificacion_rfs)\n",
    "print('_' * 60 + '\\n')\n",
    "\n",
    "\n",
    "print('\\n' + 'MSE SVM '.ljust(30,'.') + f' {mse_modelo_clasificador_svm_s:.4f}'.rjust(10, '.'))\n",
    "\n",
    "print('\\n' + '=' * 60 + '\\n')\n",
    "print('MATRIZ DE CONFUSIÓN SVM\\n')\n",
    "print(matriz_confusion_svm_s)\n",
    "print('\\n' + '=' * 60)\n",
    "\n",
    "print('INFORME DE CLASIFICACIÓN SVM\\n')\n",
    "print(informe_clasificacion_svm_s)\n",
    "print('_' * 60 + '\\n')\n",
    "\n",
    "print('\\n' + 'MSE REGRESION LOGÍSTICA '.ljust(30,'.') + f' {mse_modelo_clasificador_lr:.4f}'.rjust(10, '.'))\n",
    "\n",
    "print('\\n' + '=' * 60 + '\\n')\n",
    "print('MATRIZ DE CONFUSIÓN REGRESION LOGISTICA\\n')\n",
    "print(matriz_confusion_lr)\n",
    "print('\\n' + '=' * 60)\n",
    "\n",
    "print('INFORME DE CLASIFICACIÓN REGRESION LOGISTICA\\n')\n",
    "print(informe_clasificacion_lr)\n",
    "print('\\n' + '=' * 60)\n",
    "\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 12))\n",
    "\n",
    "sns.heatmap(ax=axes[0, 0], data=matriz_confusion_porcentajes_lr, annot=True, fmt='.2f', cmap='Blues', cbar=True)\n",
    "\n",
    "axes[0, 0].set_title('Matriz de Confusión Regresíon Logística', fontsize=10)\n",
    "axes[0, 0].set_xlabel('Predicción')\n",
    "axes[0, 0].set_ylabel('Etiqueta Verdadera')\n",
    "axes[0, 0].set_xticks([0.5 , 1.5])\n",
    "axes[0, 0].set_yticks([0.5 , 1.5])\n",
    "axes[0, 0].set_xticklabels(['No Arresto', 'Arresto'])\n",
    "axes[0, 0].set_yticklabels(['No Arresto', 'Arresto'])\n",
    "\n",
    "sns.heatmap(ax=axes[0, 1], data=matriz_confusion_porcentajes_svm_s, annot=True, fmt='.2f', cmap='Reds', cbar=True)\n",
    "\n",
    "axes[0, 1].set_title('Matriz de Confusión SVM', fontsize=10)\n",
    "axes[0, 1].set_xlabel('Predicción')\n",
    "axes[0, 1].set_ylabel('Etiqueta Verdadera')\n",
    "axes[0, 1].set_xticks([0.5 , 1.5])\n",
    "axes[0, 1].set_yticks([0.5 , 1.5])\n",
    "axes[0, 1].set_xticklabels(['No Arresto', 'Arresto'])\n",
    "axes[0, 1].set_yticklabels(['No Arresto', 'Arresto'])\n",
    "\n",
    "sns.heatmap(ax=axes[1, 0], data=matriz_confusion_porcentajes_rfs, annot=True, fmt='.2f', cmap='Greens', cbar=True)\n",
    "\n",
    "axes[1, 0].set_title('Matriz de Confusión Random Forest', fontsize=10)\n",
    "axes[1, 0].set_xlabel('Predicción')\n",
    "axes[1, 0].set_ylabel('Etiqueta Verdadera')\n",
    "axes[1, 0].set_xticks([0.5 , 1.5])\n",
    "axes[1, 0].set_yticks([0.5 , 1.5])\n",
    "axes[1, 0].set_xticklabels(['No Arresto', 'Arresto'])\n",
    "axes[1, 0].set_yticklabels(['No Arresto', 'Arresto'])\n",
    "\n",
    "sns.heatmap(ax=axes[1, 1], data=matriz_confusion_porcentajes, annot=True, fmt='.2f', cmap='Purples', cbar=True)\n",
    "\n",
    "axes[1, 1].set_title('Matriz de Confusión Árbol de Decisión', fontsize=10)\n",
    "axes[1, 1].set_xlabel('Predicción')\n",
    "axes[1, 1].set_ylabel('Etiqueta Verdadera')\n",
    "axes[1, 1].set_xticks([0.5 , 1.5])\n",
    "axes[1, 1].set_yticks([0.5 , 1.5])\n",
    "axes[1, 1].set_xticklabels(['No Arresto', 'Arresto'])\n",
    "axes[1, 1].set_yticklabels(['No Arresto', 'Arresto'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de los 4 estimadores creados, el de mejor rendimiento bajo distintos parámetros es Super Vector Machine.  Destaca con un MSE de 0.0336, el más bajo de los modelos probados.  También destaca su rendimiento al examinar los estimadores en matriz de confusión donde podemos tener información de otras métricas para clasificadores como accuracy, precision, recall y f1_score.  Acá también posee los mejores números por lo que en cuanto a las métricas elegidas se sugiere el uso de SVM como modelo de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus (20 pts)\n",
    "¿Qué puede hacer para mejorar la predicción de los modelos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos puntos que creo mejorarían en el rendimiento del modelo son por ejemplo una mirada distinta en la política de datos de entrenamiento y testeo cambiando respecto al criterio de ratio como también la aleatoridad sobre la elección de los datos.  El análisis exploratorio debe ser más acusioso y obtener algunas métricas que podrían resultar útiles en el filtrado de las variables.  Pienso que estas dos miradas respecto al uso de los datos en la construcción de un modelo más eficiente serían muy útiles para mejorar las métricas y obtener un producto mucho más fiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
